{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7puj_brTrt2",
        "outputId": "1836c522-e6e8-4336-be21-1296bef85288"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Segmentation Models: using `keras` framework.\n"
          ]
        }
      ],
      "source": [
        "# @Author:  zihaowang\n",
        "# @Email:   zihao.wang20@alumni.imperial.ac.uk\n",
        "# @Website: www.wangzihao.org\n",
        "# @Date:    2021-01-21 23:43:14\n",
        "# @Last Modified by:   zihaowang\n",
        "# @Last Modified time: 2021-03-28 22:24:36\n",
        "\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "import sys\n",
        "sys.path.append(\"../src\")\n",
        "\n",
        "import cv2\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import segmentation_models as sm\n",
        "sm.set_framework('keras')\n",
        "import ad_seg_utils as seg_utils\n",
        "import bb_eval_utils as eval_utils\n",
        "import csv\n",
        "import math\n",
        "import matplotlib.path as pltPath"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGhkksZXTrt4"
      },
      "outputs": [],
      "source": [
        "SEGMENTATION = \"skin\"\n",
        "PERTURBATION = \"noise\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PN6KwitSTrt5"
      },
      "outputs": [],
      "source": [
        "def compute_robustness_iou(true_mask, ref_boxes, perturbed_boxes):\n",
        "\tref_region = np.zeros(shape=true_mask.shape[0:2], dtype=np.int8)\n",
        "\tperturbed_region = np.zeros(shape=true_mask.shape[0:2], dtype=np.int8)\n",
        "\n",
        "\t# coordinate transformation\n",
        "\tfor box in ref_boxes:\n",
        "\t\tfor point in box:\n",
        "\t\t\tpoint[1] = true_mask.shape[0] - point[1]\n",
        "\tfor box in perturbed_boxes:\n",
        "\t\tfor point in box:\n",
        "\t\t\tpoint[1] = true_mask.shape[0] - point[1]\n",
        "\n",
        "\t# iterate over all pixels to find which of them are contained in reference prediction\n",
        "\t# and which of them are contained in perturbed prediction\n",
        "\tfor i in range(true_mask.shape[0]):\n",
        "\t\tfor j in range(true_mask.shape[1]):\n",
        "\t\t\t# iterate through all the boxes to check if pixel is inside any of them\n",
        "\t\t\tfor box in ref_boxes:\n",
        "\t\t\t\tpath = pltPath.Path([box[0], box[1], box[2], box[3]])\n",
        "\t\t\t\tif path.contains_points([[j, true_mask.shape[0] - i]]):\n",
        "\t\t\t\t\t# count pixels in both ground truth mask and boxes (TP)\n",
        "\t\t\t\t\tref_region[i, j] += 1\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\tfor box in perturbed_boxes:\n",
        "\t\t\t\tpath = pltPath.Path([box[0], box[1], box[2], box[3]])\n",
        "\t\t\t\tif path.contains_points([[j, true_mask.shape[0] - i]]):\n",
        "\t\t\t\t\t# count pixels in both ground truth mask and boxes (TP)\n",
        "\t\t\t\t\tperturbed_region[i, j] += 1\n",
        "\t\t\t\t\tbreak\n",
        "\n",
        "\tintersection = np.multiply(ref_region, perturbed_region)\n",
        "\tunion = np.add(ref_region, perturbed_region)\n",
        "# \tprint(\"max: \", np.max(intersection))\n",
        "\tnb_intersection = np.sum([pixel > 0 for pixel in intersection])\n",
        "\tnb_union = np.sum([pixel > 0 for pixel in union])\n",
        "\tIoU = 0 if nb_union == 0 else nb_intersection / nb_union\n",
        "\n",
        "\tprint(\"IoU: \", IoU)\n",
        "# \tplt.figure(dpi=1200)\n",
        "# \tplt.tight_layout()\n",
        "\t\n",
        "\tplt.subplot(333)\n",
        "\tplt.box(False)\n",
        "\tplt.axis('off')\n",
        "\tplt.imshow(ref_region)\n",
        "\tplt.title(\"unpert boxes\")\n",
        "    \n",
        "\n",
        "\tplt.subplot(336)\n",
        "\tplt.box(False)\n",
        "\tplt.axis('off')\n",
        "\tplt.imshow(perturbed_region)\n",
        "\tplt.title(PERTURBATION + \" boxes\")\n",
        "\n",
        "\tplt.subplot(337)\n",
        "\tplt.box(False)\n",
        "\tplt.axis('off')\n",
        "\tplt.imshow(union)\n",
        "\tplt.title(\"union\")\n",
        "\n",
        "\tplt.subplot(338)\n",
        "\tplt.box(False)\n",
        "\tplt.axis('off')\n",
        "\tplt.imshow(intersection)\n",
        "\tplt.title(\"intersection\")\n",
        "\t\n",
        "    \n",
        "\treturn IoU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QNo08lSTrt5"
      },
      "outputs": [],
      "source": [
        "\n",
        "################################ Model loading (this part will be replaced with new data type soon) ################################\n",
        "\n",
        "print(\"Program initiating... type of segmentation: \" + SEGMENTATION + \", type of perturbation: \" + PERTURBATION)\n",
        "\n",
        "BIN_SEG = True\n",
        "CLASSES = ['background', 'skin']\n",
        "WEIGHTS = np.array([1, 1])\n",
        "target_idx = 1\n",
        "MODEL_NAME = '/epoch34Save/skin_old_cb2_ce/old_cb2_skin_ce.h5'\n",
        "BACKBONE = 'efficientnetb3'\n",
        "LR = 0.0001\n",
        "\n",
        "# set parameters based on the type of segmentation\n",
        "if SEGMENTATION == 'SKIN' or SEGMENTATION == 'skin':\n",
        "    pass\n",
        "elif SEGMENTATION == 'AD' or SEGMENTATION == 'ad':\n",
        "    BIN_SEG = False\n",
        "    target_idx = 2\n",
        "    CLASSES = ['background', 'skin', 'eczema']\n",
        "    WEIGHTS = np.array([1, 1, 1])\n",
        "    MODEL_NAME = '/old_cb2_ad.h5'\n",
        "else:\n",
        "    print('Unexpected type of segmentation, should be either skin or ad\\n program terminated')\n",
        "\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
        "\"\"\"# Model Evaluation\"\"\"\n",
        "# config PROJ_DIR according to your environment\n",
        "PROJ_DIR = \"/path_to_project_dir\"\n",
        "PRED_DIR = os.path.join(PROJ_DIR, 'output/predictions/' + SEGMENTATION + '_test')\n",
        "BB_DIR = os.path.join(PROJ_DIR, 'output/bounding_boxes')\n",
        "EVAL_DIR = os.path.join(PROJ_DIR, 'output/evaluations')\n",
        "MODEL_DIR = os.path.join(PROJ_DIR, 'output/models')\n",
        "DATA_DIR = os.path.join(PROJ_DIR, 'data')\n",
        "\n",
        "# new dataset\n",
        "x_ref_dir = os.path.join(DATA_DIR, 'test_set/reals')\n",
        "y_ref_dir = os.path.join(DATA_DIR, 'test_set/labels')\n",
        "x_perturb_dir = os.path.join(DATA_DIR, 'perturbed_test_sets/adversarial_test_set_' + PERTURBATION)\n",
        "print('reading ref images from: ' + str(x_ref_dir))\n",
        "print('reading perturbed images from: ' + str(x_perturb_dir))\n",
        "\n",
        "reference_dataset = seg_utils.Dataset(\n",
        "    x_ref_dir,\n",
        "    y_ref_dir,\n",
        "    classes=CLASSES,\n",
        "    augmentation=None,\n",
        "    preprocessing=seg_utils.get_preprocessing(preprocess_input),\n",
        "    is_train=False,\n",
        "    use_full_resolution=False,\n",
        "    binary_seg=BIN_SEG,\n",
        ")\n",
        "\n",
        "perturbed_dataset = seg_utils.Dataset(\n",
        "    x_perturb_dir,\n",
        "    y_ref_dir,\n",
        "    classes=CLASSES, \n",
        "    augmentation=None,\n",
        "    preprocessing=seg_utils.get_preprocessing(preprocess_input),\n",
        "    is_train=False,\n",
        "    use_full_resolution=False,\n",
        "    binary_seg=BIN_SEG,\n",
        ")\n",
        "\n",
        "model = seg_utils.load_model(dir=MODEL_DIR + MODEL_NAME, classes=CLASSES, weights=WEIGHTS)\n",
        "print('Trained model loaded!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2ReqqRgTrt6"
      },
      "outputs": [],
      "source": [
        "################################ Mask prediction and evaluation ################################\n",
        "\"\"\"# Saving Masks Predictions\"\"\"\n",
        "# save all predictions\n",
        "# clear previous predictions\n",
        "print('Creating directories and clearing previous masks...')\n",
        "os.system(\"mkdir -p \" + PRED_DIR)\n",
        "# os.system(\"rm \" + PRED_DIR + \"/*.jpg\")\n",
        "# os.system(\"rm \" + PRED_DIR + \"/*.JPG\")\n",
        "# os.system(\"rm \" + BB_DIR + \"/*.jpg\")\n",
        "# os.system(\"rm \" + BB_DIR + \"/*.JPG\")\n",
        "# os.system(\"rm \" + EVAL_DIR + \"/robustness_evaluation_\" + SEGMENTATION + \"_DA_test\" + \".csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJ7lQpiCTrt7"
      },
      "outputs": [],
      "source": [
        "print('Done! Now saving new prediction masks...')\n",
        "# create a list to store a series of IoU values\n",
        "iou = []\n",
        "\n",
        "with open(EVAL_DIR + \"/robustness_evaluation_\" + SEGMENTATION + \"_DA_test\" + \".csv\", 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Reference file name\", \"Perturbation file name\", \"IoU\"])\n",
        "# \t\tfor i in range(len(reference_dataset)):\n",
        "    low_perf_list = [8, 28, 32, 47, 61]\n",
        "#     low_perf_list = [15, 33, 54, 63, 73, 161]\n",
        "    for i in range(len(low_perf_list)):\n",
        "        low_perf_list[i] = low_perf_list[i] - 2\n",
        "    \n",
        "    for i in low_perf_list:\n",
        "        \n",
        "        # prediction for reference and perturbed images\n",
        "        ref_image, gt_mask = reference_dataset[i]\n",
        "        ref_image = np.expand_dims(ref_image, axis=0)\n",
        "        ref_pred = model.predict(ref_image)\n",
        "\n",
        "        perturbed_image, _ = perturbed_dataset[i]\n",
        "        perturbed_image = np.expand_dims(perturbed_image, axis=0)\n",
        "        perturbed_pred = model.predict(perturbed_image)\n",
        "    \n",
        "        # extract the last index to decide which mask to output. [0: background; 1: skin; 2: eczema]\n",
        "        ref_pred_img = ref_pred[0, :, :, target_idx]\n",
        "        ref_pred_img = (ref_pred_img * 255).astype(np.uint8)\n",
        "\n",
        "        perturbed_pred_img = perturbed_pred[0,:,:,target_idx]\n",
        "        perturbed_pred_img = (perturbed_pred_img * 255).astype(np.uint8)\n",
        "        \n",
        "        \n",
        "        plt.figure(dpi=400)\n",
        "        left  = 0  # the left side of the subplots of the figure\n",
        "        right = 0.8    # the right side of the subplots of the figure\n",
        "        bottom = 0   # the bottom of the subplots of the figure\n",
        "        top = 1      # the top of the subplots of the figure\n",
        "        wspace = 0   # the amount of width reserved for blank space between subplots\n",
        "        hspace = 0.3   # the amount of height reserved for white space between subplots\n",
        "        alpha = 0.5\n",
        "\n",
        "        plt.subplots_adjust(left=left, bottom=bottom, right=right, top=top, wspace=wspace, hspace=hspace)\n",
        "        \n",
        "        plt.subplot(331)\n",
        "        plt.title('unpert img')\n",
        "        plt.box(False)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(cv2.cvtColor(cv2.imread(os.path.join(x_ref_dir, reference_dataset.images_ids[i])),cv2.COLOR_BGR2RGB))\n",
        "        \n",
        "        plt.subplot(332)\n",
        "        plt.title('unpert pred')\n",
        "        plt.box(False)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(ref_pred_img)\n",
        "        \n",
        "        \n",
        "        plt.subplot(334)\n",
        "        plt.title(PERTURBATION + ' img')\n",
        "        plt.box(False)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(cv2.cvtColor(cv2.imread(os.path.join(x_perturb_dir, perturbed_dataset.images_ids[i])),cv2.COLOR_BGR2RGB))\n",
        "        \n",
        "        plt.subplot(335)\n",
        "        plt.title(PERTURBATION + ' pred')\n",
        "        plt.box(False)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(perturbed_pred_img)\n",
        "        \n",
        "\n",
        "        # save the images\n",
        "        cv2.imwrite(os.path.join(PRED_DIR, \"pred_\" + reference_dataset.images_ids[i]), ref_pred_img)\n",
        "        cv2.imwrite(os.path.join(PRED_DIR, \"pred_\" + perturbed_dataset.images_ids[i]), perturbed_pred_img)\n",
        "        print(\"saving\", reference_dataset.images_ids[i])\n",
        "        print(\"saving\", perturbed_dataset.images_ids[i])\n",
        "        \n",
        "        # generate bounding boxes for each predicted mask\n",
        "        perturbed_boxes = []\n",
        "        perturbed_pred_img = cv2.imread(os.path.join(PRED_DIR, \"pred_\" + perturbed_dataset.images_ids[i]))\n",
        "        gray = cv2.cvtColor(perturbed_pred_img,cv2.COLOR_BGR2GRAY)\n",
        "        thresh = cv2.threshold(gray,127,255,cv2.THRESH_BINARY)[1]\n",
        "        perturbed_contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        perturbed_contours = perturbed_contours[0] if len(perturbed_contours) == 2 else perturbed_contours[1]\n",
        "\n",
        "        ref_boxes = []\n",
        "        ref_pred_img = cv2.imread(os.path.join(PRED_DIR, \"pred_\" + reference_dataset.images_ids[i]))\n",
        "        gray = cv2.cvtColor(ref_pred_img, cv2.COLOR_BGR2GRAY)\n",
        "        thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)[1]\n",
        "        ref_contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        ref_contours = ref_contours[0] if len(ref_contours) == 2 else ref_contours[1]\n",
        "\n",
        "        # extract contours from perturbed predictions\n",
        "        for cntr in perturbed_contours:\n",
        "            rect = cv2.minAreaRect(cntr)\n",
        "            box = cv2.boxPoints(rect)\n",
        "            box = np.int0(box)\n",
        "            area = cv2.contourArea(cntr)\n",
        "            # Abandon boxes with too small area\n",
        "            if seg_utils.crop_filter(area):\n",
        "                perturbed_boxes.append(box)\n",
        "\n",
        "        # extract contours from reference predictions\n",
        "        for cntr in ref_contours:\n",
        "            rect = cv2.minAreaRect(cntr)\n",
        "            box = cv2.boxPoints(rect)\n",
        "            box = np.int0(box)\n",
        "            area = cv2.contourArea(cntr)\n",
        "            # Abandon boxes with too small area\n",
        "            if seg_utils.crop_filter(area):\n",
        "                ref_boxes.append(box)\n",
        "\n",
        "        # append IoU to the list\n",
        "        iou_per_image = compute_robustness_iou(gt_mask, ref_boxes, perturbed_boxes)\n",
        "        iou.append(iou_per_image)\n",
        "        writer.writerow([reference_dataset.images_ids[i], perturbed_dataset.images_ids[i], iou_per_image])\n",
        "        \n",
        "        stored_name = reference_dataset.images_ids[i]\n",
        "        stored_name =  stored_name[0:-4] + '_' + SEGMENTATION + '_' + PERTURBATION + '.eps'\n",
        "        plt.savefig(stored_name, format='eps', bbox_inches='tight', pad_inches=0.2)\n",
        "        plt.show()\n",
        "\n",
        "    # append the mean performance to the end of csv\n",
        "    writer.writerow(['mean', '', np.mean(iou)])\n",
        "    writer.writerow(['se', '', np.std(iou) / np.sqrt(len(iou))])\n",
        "\n",
        "    print('Done!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jX2rzRVTrt8"
      },
      "outputs": [],
      "source": [
        "print(gt_mask.shape[0:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iW4KPks5Trt8"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXpH4CJATrt8"
      },
      "outputs": [],
      "source": [
        "!python ../src/train_batch2.py --seg_type skin --train_dir /path_to_project_dir/data/augmented_training_set_corrected --prefix old_cb2"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "EczemaNet Python Env: SEG_DL",
      "language": "python",
      "name": "seg_dl"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}